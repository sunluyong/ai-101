## 一、什么是智能
制造一个“会思考的东西”是人类最古老的梦想之一。计算机诞生不久，人们便意识到它所蕴含的巨大潜力——于是打造“能够思考的机器”逐渐成为计算机科学的核心目标之一。

自 1956 年“人工智能”（Artificial Intelligence）概念正式提出以来，我们见证了这一领域的飞速发展：从 IBM 深蓝依靠强大的算力在国际象棋中取胜，到 AlphaGo 借助策略网络与强化学习击败人类围棋冠军，再到今天广泛落地的人脸识别与智能驾驶。然而这些成果大多仍属于“专用人工智能”：它们在各自的任务上表现卓越，却很难跨任务、跨场景迁移能力。

如今，讨论的焦点正逐渐转向通用人工智能（AGI）——一种具备类人理解、推理与学习能力，并能在不同领域中解决问题的系统。但到底什么是“智能”？

举个人类的例子：一个孩子被杯子内的开水烫过一次后，不仅会避开那个特定的杯子，还会本能地对所有冒着热气的物体保持警惕。人类并不需要把“所有会烫的东西”都试一遍，就能从一次经历中学会避险，并将经验推广到新情境中。这种“从有限经验中抽取规律，并在陌生环境中做出正确判断”的能力，正是智能的核心。

在计算机科学中，我们将其称为泛化能力。如果用一个公式来定义：

**智能 = 学习能力 + 迁移能力**

真正的智能系统，不应只是规则的执行器，而应能够从已知推导未知，从过去的经验中提炼规律，并将其有效应用到从未见过的全新场景中。

## 人工智能的演化：从“规则驱动”到“主动学习”
AlphaGo 击败围棋世界冠军已足够震撼，ChatGPT 等大语言模型展现出的“全能”表现，更让人忍不住追问：机器的智能究竟从何而来？答案或许出人意料——现代 AI 获得智能的方式，其实一直在模仿人类最朴素的学习本能，见多识广然后举一反三。

### 我们是如何认出“苹果”的？
请看下面这几张图片：

【此处展示：红苹果、被咬了一口的苹果、切开的苹果、画在纸上的苹果】

有趣的是，我们从未背诵过“苹果的精确定义”，更不知道它的几何参数、纹理方程或颜色阈值。但在反复见过无数次苹果（实物、照片、视频）之后，我们的大脑会自动从海量“样本”中提取关键特征：轮廓的弧度、表皮的光泽、果柄的位置、切面的纹理等。

神经元的连接在不断的刺激中自行调整，最终在脑海中形成了一个模糊却精准的概念——“苹果”。

更关键的是：当你第一次见到一种从未见过的苹果品种（比如颜色深紫、形状扁平、表皮带斑点）时，你依然能瞬间认出它——这就是“迁移能力”，也是智能的本质。

### AI 发展的两条路线
然而计算机科学家们花了几十年才明白这个道理，这也造就了 AI 发展史上最关键的分野——从符号主义（由规则定义世界）向联结主义（让机器自己发现规律）的范式转移：

**1）规则驱动：符号主义与专家系统**  
早期 AI 走的是“专家系统”路线：工程师试图以“上帝视角”把世界的逻辑写成代码。例如用规则定义苹果：

> 如果它是圆的、红色的、有果柄，那么它是苹果。
>

但这种方法很快碰壁，因为现实世界的变化无穷无尽：光影在变、角度在变；被咬了一口还是不是苹果？烂了一半算不算？现实世界中规则永远写不完。

**2）学习驱动：机器学习与联结主义**  
既然规则写不完，不如让机器像人类一样去“看”、去“学”。1959 年计算机科学家亚瑟·塞缪尔（Arthur Samuel）提出了一个划时代的定义：

> “机器学习，是赋予计算机无需被显式编程就能具备学习能力的研究领域。”
>

我们不再告诉计算机“怎么做”，而是把一万张苹果的照片扔给它，告诉它：“你自己看，你自己总结。”

当机器不再依赖人类硬编码的规则，而是开始从海量数据中自主归纳特征，从而真正做到见多识广、举一反三时，真正的智能才得以萌芽。

## 三、智能的基础：数据与算力
既然原理听起来如此简单，为什么 AI 直到最近十年才迎来大爆发？

经过数百万年演化的人类大脑，能以仅约 20 瓦的功率高效完成复杂的认知任务。而机器要模拟这种智能，本质上是一场依赖“暴力计算”的模拟游戏，这种“大力出奇迹”的做法，直到最近才集齐了两个关键拼图：

1. **海量数据**：数据是模型训练的养料。如同人类通过经验学习，AI 需要通过海量样本来提取规律。互联网时代沉淀的文本、图像与视频——从维基百科到社交网络，从数字化典籍到网页记录——构成了人类文明的数字化全景。这些数据为 AI 提供了规模空前的训练集，打破了早期人工智能面临的“数据匮乏”瓶颈。
2. **超强算力**：深度神经网络的训练涉及数十亿甚至万亿级参数的优化，每一次权重更新都需要海量的矩阵运算。这这种计算强度在过去是不可想象的。得益于 GPU 并行计算架构的成熟、摩尔定律的红利以及专用 AI 芯片（如 TPU）的突破，现代硬件终于能够支撑起如此庞大的算力需求。

数据与算力，是智能得以落地的物理基础，二者缺一不可。正是它们在近十年的同步跃升，才把人工智能从实验室里的论文与原型，推向了每个人的手机屏幕。

## 四、寻找上帝公式：模型的本质
那么机器学会了之后，它脑袋里装的到底是什么？答案就是——**模型（Model）**。

<font style="color:rgb(46, 43, 41);">让我们回想中学数学，有一堆数据点散落在坐标系上，老师让我们“找到一条曲线来拟合它们”。这条曲线就是一个函数 </font>$ f(x)=y $<font style="color:rgb(46, 43, 41);">，它描述了输入和输出之间的关系。</font>

机器学习的本质，就是在做同样的事情，只不过规模大到令人眩晕

+ 输入一张图片，输出"苹果"——这是一个函数
+ 输入一段语音，输出对应的文字——这是一个函数
+ 输入一句话的前半句，输出最可能的下半句——这也是一个函数

机器学习“找到”的这个函数，就叫做模型。它是机器从海量数据中提炼出的“规律”的数学表达。训练一个 AI 模型，本质上就是在天文数字级别的参数空间里，通过不断试错与优化，搜索出那个最能解释数据背后规律的函数。



印度天才数学家拉马努金曾写出一个计算圆周率的公式

$ \begin{equation}
\frac{1}{\pi} = \frac{2\sqrt{2}}{9801} \sum_{k=0}^{\infty} \frac{(4k)! \, (1103 + 26390k)}{(k!)^4 \, 396^{4k}}
\nonumber
\end{equation} $

它看起来怪诞离奇，但收敛得极快，每多算一项就能多获得约 8 位精确小数。同时代的数学家们看着这个公式，感到既震惊又困惑：它是正确的，但没人知道他是怎么想到的。

这提醒我们：世界中确实存在更深层的规律与结构，只是人脑的算力与记忆容量有限，无法仅凭直觉触及所有隐藏的秩序。拉马努金的公式像是天才偶然“摸到”了某种深层结构的边缘；而今天的 AI 模型则将这种探索变成了可规模化、可重复的系统工程——在庞大的数据与参数空间里持续逼近那些能更好描述世界的“规律表达式”。

## 五、人工智能发展的三个阶段
人工智能的发展史，是从统计方法向通用认知进化的过程，其技术范式经历了三次重大的迭代。

第一阶段是**机器学习（Machine Learning）**，可以说是统计学的胜利。

它的核心转变在于从“规则驱动”走向“数据驱动”：不再主要依赖人类预设的硬性规则，而是通过数据学习概率关系。典型例子是垃圾邮件分类器——它并不真正理解“垃圾邮件”是什么，但会从大量样本中统计出某些词组合出现时为垃圾邮件的概率极高，例如同时出现“中奖”“汇款”“恭喜”时，模型就会给出接近 99% 的风险判断。

这个阶段的局限也很明显：模型效果高度依赖人类专家的特征工程，数据怎么清洗、选哪些特征、如何表达问题，往往决定了模型能走多远；机器本质上仍是在“人类画好的框”里做优化。



第二阶段是**深度学习（Deep Learning）**，标志着感知智能的觉醒。

其核心思想是用多层神经网络的层级结构模拟人脑的信息处理方式，让模型能够从原始数据中自动学习特征。机器开始学会像人一样“看”和“听”，能从图像中逐层抽取边缘、纹理、形状等特征，最终识别出“这是一只猫”。这一时期涌现了许多代表性成果，例如人脸识别、语音识别等广泛落地的应用；AlphaGo 则是深度学习阶段的巅峰之一，它在围棋这种规则封闭、信息完备的对弈环境中展现出超越人类的“直觉式”策略能力。

不过深度学习通常仍偏专用智能，模型可以在特定任务上做到极强，但缺乏跨任务迁移的通用理解，更谈不上大规模的语言生成与综合推理。



第三阶段是**大语言模型（LLM）**，也就是生成式 AI 的兴起。

它以 Transformer 架构为基础，通过自注意力机制和“下一个词预测”这一训练范式，让模型在海量文本中学习语言结构、知识关联与表达方式。这一阶段的关键变化是：AI 不再主要做“选择题”（分类、判别），而是开始写“作文”（生成、续写、总结、对话），在某些场景下甚至能在交互层面接近或通过图灵测试。

ChatGPT、Claude、Gemini 等是这一阶段的代表，它们展示了跨领域的通用问题解决能力，使得我们与 AGI 的距离在观感上前所未有地接近——AI 开始不仅能完成任务，还能以语言为媒介进行综合、推理与创造。

## 六、语言即世界：通往认知智能的钥匙
在很长一段时间里，人们认为图像识别更难，但最终率先通过图灵测试、展现出认知智能的是以 ChatGPT 为代表的大语言模型，为什么是语言模型？

### 语言是世界的压缩
奥地利哲学家维特根斯坦曾说：

> "我的语言之界限，即我世界之界限。"
>

语言不仅仅是交流的工具，它是人类对世界运行逻辑的高度压缩

+ 当我们说"因为下雨，所以地湿了"，这里面编码了因果律
+ 当我们说"虽然……但是……"，这里面编码了逻辑转折
+ 当我们描述"悲伤"，这里面编码了人类的情感模型
+ 当我们讲述一个故事，这里面编码了时间、空间、人物关系和社会规范

人类几千年的文字记录——从哲学论著到法律条文，从科学论文到市井小说——本质上是人类对世界全量认知的文本化存储。

### 预测下一个字，就是理解世界
大语言模型的训练目标看起来简单得有些令人惊讶：预测下一个字（token）是什么。

但不要小看这个任务。为了准确预测“今天天气真”后面是“好”还是“热”，模型被迫去“理解”语境。当文本变得足够复杂，为了预测物理题的答案、代码的下一行或故事的结局，模型必须在内部构建出物理规律、编程逻辑和人类心理的映射。

+ 要预测一个物理题的答案，它必须学会物理规律
+ 要预测一个故事的结局，它必须学会人物动机和情感逻辑
+ 要预测一段代码的下一行，它必须学会编程语言的语法和逻辑

随着文本变得越来越复杂，为了预测的准确，模型被迫去"理解"越来越深层的东西，通过学习人类所有的文字记录，它实际上是在学习人类对这个世界的全量认知。这时候大语言模型“涌现”出惊人的能力——它似乎理解了逻辑、因果和常识，能够进行推理、创作代码、甚至模仿人类的情感。

## 七、另一种声音：空间智能与被遗忘的五亿年
语言模型的成功让很多人相信，沿着这条路走下去就能抵达 AGI，但并非所有顶尖学者都同意这个判断。

斯坦福大学教授、ImageNet 的缔造者李飞飞提出了一个深刻的反共识观点：大语言模型无法通往 AGI，空间智能才是最优路径。

她的论据来自生物进化史本身，语言在生物演化的长河中只是最近50万年的产物——它年轻得像是昨天才出现。而视觉与触觉所代表的空间智能，早在5亿年前的寒武纪就开启了神经系统的演化竞赛。 正是"看见"这个世界的能力，驱动了大脑的爆发式进化。动物为了捕食和逃跑，必须在三维空间中感知距离、判断速度、预测轨迹——这才是智能最原始、最深层的根基。

在李飞飞看来，如果AI无法理解三维物理世界，无法具备物理直觉——比如一个球被推下桌子会怎样，一杯水倒过来会发生什么——它就只能被永远困在数字的像素和文字的符号中，永远无法真正"理解"这个世界。

带着这样的判断，李飞飞创办了World Labs，试图走通一条不同于 OpenAI 的路径：通过构建具有物理一致性的世界模型，为 AI 补上感知与空间理解的短板。

这场关于"通往 AGI 之路究竟是什么"的辩论，揭示了一个更深层的真相：我们对"智能"的理解，本身就仍在进化中。 语言是世界的一面镜子，但镜子终究不是世界本身。或许最终的答案是——语言智能与空间智能，如同认知的双翼，缺一不可。

## 结语
到这里，我们已经知道人工智能本质上是从有限经验中提炼规律，并将这些规律迁移到新的情境里去解决问题的能力。但机器究竟是如何被一步步训练出这种能力的？

当数据与经验可以被大规模获取时，关键就变成了如何把这些数据变成可学习的任务，让机器在反复试错中自己学出规律。

这就是机器学习课程要解决的核心问题！  